{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4129795-b2f3-455a-816d-7f9d7e9c5d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import uniform\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "975440ec-8f56-418c-9818-fbece76a5e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.36733216,  1.42484899,  1.39771176, ...,  1.23821508,\n",
       "         1.03256375, -0.61393228],\n",
       "       [-1.64262117, -1.38821735, -1.69983868, ..., -1.65940326,\n",
       "        -1.34028771, -0.61393228],\n",
       "       [-0.12491496,  0.23157057,  0.27974756, ...,  0.08400417,\n",
       "         0.76891358,  1.62884414],\n",
       "       ...,\n",
       "       [ 0.87057643,  0.98936095,  0.88373528, ..., -0.66004487,\n",
       "         0.76891358, -0.61393228],\n",
       "       [-0.43303746, -0.62438274, -0.1681792 , ...,  0.10019118,\n",
       "        -0.6811623 , -0.61393228],\n",
       "       [-0.0053817 , -0.19750606, -0.20137148, ...,  0.31796349,\n",
       "         1.16438883, -0.61393228]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with open(\"X_train_scaled.pkl\", \"rb\") as f:\n",
    "    X_train_scaled = pickle.load(f)\n",
    "\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00fb582b-3360-4a57-a378-160b244133c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.60365708,  0.1062256 , -0.48741598, ..., -0.57388629,\n",
       "        -0.6811623 , -0.61393228],\n",
       "       [ 1.3989636 ,  1.34885406,  1.28012826, ...,  0.84255533,\n",
       "         0.10978818, -0.61393228],\n",
       "       [-0.24874829, -0.62438274, -0.48189014, ..., -0.78401147,\n",
       "        -0.81298739, -0.61393228],\n",
       "       ...,\n",
       "       [ 0.92084444,  0.968366  ,  0.99940568, ...,  1.17614635,\n",
       "        -0.6811623 , -0.61393228],\n",
       "       [ 1.22718252,  1.42484899,  1.40183995, ...,  1.45277269,\n",
       "        -1.20846263, -0.61393228],\n",
       "       [ 0.40642961, -0.46174402,  0.00713792, ..., -0.61205156,\n",
       "        -1.20846263,  1.62884414]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"X_test_scaled.pkl\", \"rb\") as f:\n",
    "    X_test_scaled = pickle.load(f)\n",
    "    \n",
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de2cc303-3ae3-4811-9d01-a337a8b3d6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135075    3115.0\n",
       "48411       56.0\n",
       "71197      637.0\n",
       "129903    2298.0\n",
       "129682     338.0\n",
       "           ...  \n",
       "114927     316.0\n",
       "124946    1782.0\n",
       "108064    1754.0\n",
       "137499     577.0\n",
       "127112     697.0\n",
       "Name: Actual_trip_time, Length: 110763, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"y_train.pkl\", \"rb\") as f:\n",
    "    y_train = pickle.load(f)\n",
    "    \n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec98a323-ffa6-4f82-923e-1d985f8048cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18349      348.0\n",
       "53820     2795.0\n",
       "7120       436.0\n",
       "56892     3045.0\n",
       "124410    1466.0\n",
       "           ...  \n",
       "137146      67.0\n",
       "96916       73.0\n",
       "110154    2175.0\n",
       "113117    2831.0\n",
       "69526     1103.0\n",
       "Name: Actual_trip_time, Length: 27691, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"y_test.pkl\", \"rb\") as f:\n",
    "    y_test = pickle.load(f)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eeb94df-bf91-422c-82f8-ee1748c36365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import uniform\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69b4ff80-3ea4-4d81-814d-fab2ed3eeb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV R2 Score: 0.8941122710044593\n",
      "RandomizedSearchCV RMSE: 351.5230770360603\n",
      "Best alpha: 2.0684494295802445\n"
     ]
    }
   ],
   "source": [
    "# Define parameter distribution\n",
    "\n",
    "param_dist = {'alpha': uniform(0.01,100)}\n",
    "\n",
    "# Initialize model\n",
    "lasso = Lasso(max_iter=10000)\n",
    "\n",
    "# Randomized search\n",
    "random_search = RandomizedSearchCV(lasso, param_distributions=param_dist,\n",
    "                                   n_iter=20, cv=5, scoring='neg_mean_squared_error',\n",
    "                                   random_state=42)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model\n",
    "best_lasso_random = random_search.best_estimator_\n",
    "\n",
    "# Evaluate\n",
    "y_pred_random = best_lasso_random.predict(X_test_scaled)\n",
    "print(\"RandomizedSearchCV R2 Score:\", r2_score(y_test, y_pred_random))\n",
    "print(\"RandomizedSearchCV RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_random)))\n",
    "print(\"Best alpha:\", random_search.best_params_['alpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "646b9c6a-4c46-4018-9ec9-0877d191ad10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "R² Score: 0.9999764499319337\n",
      "RMSE: 5.242363214531646\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR² Score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, r2_score(y_test, y_pred))\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE:\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_test, y_pred)))\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, grid\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Define the model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],            # Number of trees\n",
    "    'max_depth': [None, 10, 20, 30],            # Depth of tree\n",
    "    'min_samples_split': [2, 5, 10],            # Min samples to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],              # Min samples at a leaf node\n",
    "    'max_features': ['sqrt', 'log2',1]          # Features to consider at each split\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "random_search = RandomizedSearchCV(estimator=rf,\n",
    "                                   param_distributions=param_grid,\n",
    "                                   n_iter=20,   # Number of parameter settings that are sampled.\n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   cv=5,\n",
    "                                   n_jobs=-1, # Number of jobs to run in parallel( -1 means using all processors)\n",
    "                                   random_state=42,\n",
    "                                   verbose=2) # Controls the verbosity: the higher, the more messages.\n",
    "\n",
    "# Fit on training data (use scaled X_train if scaling was done)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(\"Best Hyperparameters:\\n\", random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "006324dd-2ef7-4ad5-a11c-f6de25e8eb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      " {'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters:\\n\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df8e1d0-4a17-40e1-adf1-5eb642fe41d8",
   "metadata": {},
   "source": [
    "**(R-squared) measures how well our model's predictions match the actual values.**\n",
    "\n",
    "It ranges from:\n",
    "\n",
    "1.0 → Perfect prediction.\n",
    "\n",
    "0.0 → Model predicts no better than the mean.\n",
    "\n",
    "< 0.0 → Model is worse than just predicting the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0045b397-d933-49bf-a2f7-ae3c302d75e3",
   "metadata": {},
   "source": [
    "**Root Mean Squared Error (RMSE)** measures the average magnitude of the prediction error — in the same units as your target variable.\n",
    "\n",
    "1. It's always non-negative.\n",
    "2. Lower RMSE = Better fit.\n",
    "3. If our target variable has a wide range, RMSE of 5.24 might be very small, suggesting excellent predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b23546f-45db-436e-8dec-3f927e8d4c3d",
   "metadata": {},
   "source": [
    "### Let's check the scale of the Target variable\n",
    "If our y_test values range from 0 to 1000, RMSE = 5.24 is excellent.\n",
    "\n",
    "But if the target values are between 0 and 10, it's relatively large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a48790-db5a-4206-ae80-35f570be5df1",
   "metadata": {},
   "source": [
    "### Comparison with Standard Deviation of y_test:\n",
    "If std_dev >> RMSE, your model is performing well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cab18258-b5b8-4fbe-871f-066b7b6cd365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1080.266787864038"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c65f99-bf1f-4372-902c-58a82a20c7a1",
   "metadata": {},
   "source": [
    "**RMSE is very small compared to std deviation:**\n",
    "\n",
    "Our target variable naturally varies by ±1080 units, but our model's average error is only ~5.24 units.\n",
    "\n",
    "That means your model is **capturing almost all of the natural variance in the data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e44a9c0-3e20-42a7-b910-7a1ec9d553bf",
   "metadata": {},
   "source": [
    "### Let’s check for overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba845e-01e2-4462-b5a2-1e53c7998c48",
   "metadata": {},
   "source": [
    "How to Detect Overfitting?\n",
    "\n",
    "We compare performance on training vs. test data using metrics like:\n",
    "\n",
    "R² Score\n",
    "\n",
    "RMSE\n",
    "\n",
    "Cross-Validation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77556f41-a62e-468e-bb0d-73ec7ca908f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R² Score: 0.9999947593825038\n",
      "Train RMSE: 2.4671257447789827\n"
     ]
    }
   ],
   "source": [
    "# 1. Check R² and RMSE on Training Data\n",
    "y_train_pred = best_rf.predict(X_train_scaled)\n",
    "\n",
    "print(\"Train R² Score:\", r2_score(y_train, y_train_pred))\n",
    "print(\"Train RMSE:\", np.sqrt(mean_squared_error(y_train, y_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b820b9d-b72e-47b1-86e4-936cf9f9d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Compare With Test Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae78bc69-6a19-40c3-bef0-912d4f6124d8",
   "metadata": {},
   "source": [
    "**If training R² is also ~0.9999 and RMSE is similar (i.e., no large gap), no overfitting is likely**\n",
    "\n",
    "So below are the finding for calculating R² and RMSE on Test Data(original way) and on Train Data.\n",
    "\n",
    "\n",
    "Test R² Score: 0.9999764499319337 | Test RMSE: 5.242363214531646\n",
    "\n",
    "Train R² Score: 0.9999947593825038 Train RMSE: 2.4671257447789827\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cb83bcf7-68a8-4969-88ae-afe702778c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validated R² Scores: [0.99996685 0.99996446 0.99996011 0.99996202 0.99996193]\n",
      "Mean CV R²: 0.999963075115385\n"
     ]
    }
   ],
   "source": [
    "# 3 Run K-Fold Cross-Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(best_rf, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "print(\"Cross-Validated R² Scores:\", cv_scores)\n",
    "print(\"Mean CV R²:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ccc758-d023-4671-91f5-d6ba3cd6bc7b",
   "metadata": {},
   "source": [
    "1. Extremely High R² Across All Folds:-\n",
    "   \n",
    "**All the values are consistently around 0.99996, which is very stable. No large drop in any fold.**\n",
    "\n",
    "2. Low Variance Between Folds\n",
    "   \n",
    "**The difference between the best and worst R² is very small (~0.000006), meaning:** \n",
    "\n",
    "Our model generalizes well across different splits of the data and It's not overly sensitive to specific subsets of our training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb08501c-8d01-49f0-9e91-38b8fd30afd1",
   "metadata": {},
   "source": [
    "## Is our Model overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3ac6b3-8281-4462-867b-1d995ba36abd",
   "metadata": {},
   "source": [
    "Mean R² (CV) ≈ Test R² ≈ Train R²\n",
    "\n",
    "1. Train R²: ~0.999994\n",
    "2. Test R²: ~0.999976\n",
    "3. Mean CV R²: ~0.999963\n",
    "   \n",
    "This consistency across training, validation, and testing is a strong sign of a **robust model**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc450e0-b435-45d0-8d66-994ccfabd094",
   "metadata": {},
   "source": [
    "Our model is **not overfitting** in any harmful way.\n",
    "\n",
    "It may appear to be “too good,” but the cross-validation and test metrics both support its strong generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68c84c67-e42d-4860-9003-f6dbfee98bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbmNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in f:\\new folder\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in f:\\new folder\\lib\\site-packages (from lightgbm) (1.13.1)\n",
      "Downloading lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 0.8/1.5 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 4.8 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7193b3e2-cf9b-4fc8-8691-e6e7ceabb36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3361\n",
      "[LightGBM] [Info] Number of data points in the train set: 110763, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 1114.145143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\New folder\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'subsample': 1.0, 'num_leaves': 150, 'n_estimators': 1000, 'min_child_samples': 20, 'max_depth': 15, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "R² Score on Test: 0.9999992991250947\n",
      "RMSE on Test: 0.9043806869540412\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Define the model\n",
    "lgbm = LGBMRegressor(random_state=42)\n",
    "\n",
    "# Step 2: Hyperparameter search space\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 500, 1000],\n",
    "    'learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "    'max_depth': [-1, 5, 10, 15],\n",
    "    'num_leaves': [31, 50, 100, 150],\n",
    "    'min_child_samples': [5, 10, 20, 50],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Step 3: RandomizedSearchCV setup\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lgbm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring='r2',\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Step 4: Fit on training data\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 5: Evaluate\n",
    "best_lgbm = random_search.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_lgbm.predict(X_test_scaled)\n",
    "\n",
    "# Metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "print(\"R² Score on Test:\", r2)\n",
    "print(\"RMSE on Test:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b94220a-4fc2-48c1-8d55-a05d8403f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model\n",
    "with open(\"best_lgbm_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_lgbm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6188bb-589e-469f-b201-bdd322589416",
   "metadata": {},
   "source": [
    "### Let’s check for if LightGbm model is overfitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "185ff636-91cc-4f69-b341-7738f7b1348d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\New folder\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R² Score: 0.9999998776652881\n",
      "Train RMSE: 0.3769423256876934\n"
     ]
    }
   ],
   "source": [
    "# 1. Check R² and RMSE on Training Data\n",
    "y_train_pred = best_lgbm.predict(X_train_scaled)\n",
    "\n",
    "print(\"Train R² Score:\", r2_score(y_train, y_train_pred))\n",
    "print(\"Train RMSE:\", np.sqrt(mean_squared_error(y_train, y_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f887f18-da1d-4c7f-8e39-3db0054c3f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3359\n",
      "[LightGBM] [Info] Number of data points in the train set: 88610, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 1116.124376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\New folder\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3361\n",
      "[LightGBM] [Info] Number of data points in the train set: 88610, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 1113.480155\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\New folder\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3357\n",
      "[LightGBM] [Info] Number of data points in the train set: 88610, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 1113.058086\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\New folder\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3357\n",
      "[LightGBM] [Info] Number of data points in the train set: 88611, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 1113.827031\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\New folder\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3357\n",
      "[LightGBM] [Info] Number of data points in the train set: 88611, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 1114.236071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\New folder\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validated R² Scores: [0.99999888 0.99999875 0.99999848 0.99999865 0.99999769]\n",
      "Mean CV R²: 0.9999984912189991\n"
     ]
    }
   ],
   "source": [
    "# 2. Use a Validation Set or Cross-Validation - Instead of only train/test, split into train/valid/test or use K-Fold CV:\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(best_lgbm, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "print(\"Cross-Validated R² Scores:\", cv_scores)\n",
    "print(\"Mean CV R²:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd69a6-cccc-44f9-9519-8ab6cd573cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca76ec33-c880-40e5-b099-4ef970bdcc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90e1286-e713-478c-96aa-377fb23f69e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9336a6e-4f1d-4948-9b24-ff74bf145ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c17e177-10c4-4930-99ba-b97b75a52e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa25642b-8317-4de4-ac7e-c862f9d99168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d470a7fe-ad95-4b38-979f-b7237350548b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a533050-ccc9-456c-a05e-a95e55282286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b459f0-2417-4727-afa2-d683c2927622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585e62f5-d216-46e2-accb-3154aacbfc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be796a-b627-4283-a542-7fae87d53b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
